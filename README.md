# MultiModelProxy

An OAI-compatible proxy server that facilitates fast Chain of Thought generation thought prompting by using a smaller model to do the CoT inference before handing it to the (larger) main model.

# License

This project is licensed under AGPLv3.0 (see included LICENSE file). The following clause applies on top of it and overrides any conflicting clauses:

**This project may not be used in a commercial context under any circumstance unless a commercial license has been granted by the owner. This stipulation applies on top of the
AGPLv3 license.**